{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install transformers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport json\n\nimport transformers\nimport torch\n\nfrom typing import List\nimport warnings","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_json_names(dirname = '/kaggle/input'):    \n    jsons = []\n    for dirname, _, filenames in os.walk('/kaggle/input'):\n        for filename in filenames:\n            if filename.endswith('json'):\n                jsons.append(os.path.join(dirname, filename))\n    return sorted(jsons)\n\ndef read_text_entries(json_file):\n    with open(json_file, 'r') as f:\n        js = json.loads(f.read())\n        text_entries = []\n        for entry in js['body_text']:\n            text_entries.append(entry['text'])\n        all_text = \"\\n\".join(text_entries)\n    return all_text \n    \ndef read_texts(json_files, max_texts=1000):\n    if max_texts is None:\n        max_texts = len(json_files)\n    texts = []\n    for i, file_ in enumerate(json_files):\n        if i > max_texts:\n            return texts\n        else:\n            text = read_text_entries(file_)\n            texts.append(text)\n            \nBEGIN = \"[CLS]\"\nSEP = \"[SEP]\"\n\ndef _get_top_inds(scores, top_k):\n    best_inds = torch.flatten(\n        torch.narrow(torch.argsort(scores, descending=True), \n                     dim=1, start=0, length=top_k))\n    # print(best_inds)\n    best_scores = torch.index_select(scores, 1, best_inds)\n    \n    return best_inds, best_scores\n\ndef _answer_ok(answer):\n    return answer.strip() != BEGIN and SEP not in answer and answer != ''\n\ndef _get_token_type_ids(input_ids):\n    ## Why 102?? unsolved..\n    return [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))] \n        \nclass Answerer:\n    def __init__(self, model, tokenizer, texts: List[str], max_tokens = 512, max_answers = 3):\n        self.model = model\n        self.tokenizer = tokenizer\n        self.max_tokens = max_tokens\n        self.texts = texts\n        self.max_answers = 3\n        \n    def _encode_question(self, question: str) -> List[int]:\n        \"\"\"\n        Encodes the question to integer, truncating and warning if the question\n        was longer than self.max_tokens.\n        \"\"\"\n        question = f\"{BEGIN} {question}\"        \n        question_ids = self.tokenizer.encode(question)\n        if len(question_ids) > self.max_tokens:\n            warnings.warn(\n                f\"question longer than {self.max_tokens} tokens \" +\n                f\"it's {len(question_ids)} tokens long); truncating.\")\n            question_ids = question_ids[:max_tokens]\n        return question_ids\n    \n    def _encode_text(self, text: str, question_length: int) -> List[List[int]]:\n        \"\"\"\n        Encodes the tokens in text to integers, using this objects tokenizer.\n        :returns: the full text, encoded as integers, split into partitions of length \n        self.max_tokens - question_length.\n        \"\"\"\n        text = f\"{SEP} {text} {SEP}\"\n        text_ids = self.tokenizer.encode(text)\n        i = 0\n        step = self.max_tokens - question_length\n        text_id_subsets = []\n        while i < len(text_ids):\n            text_id_subset = text_ids[i:(i + step)]\n            text_id_subsets.append(text_id_subset)\n            i += step\n        return text_id_subsets\n\n    def _find_answer(self, input_ids: List[str]) -> str:\n        \"\"\"\n        Returns the model's prediction for what the answer is for the input ids.\n        \n        :param input_ids: a full question; text string, encoded to a List of integer.\n        \"\"\"\n        token_type_ids = _get_token_type_ids(input_ids)\n        input_ids_tensor = torch.tensor([input_ids])        \n        token_type_ids_tensor = torch.tensor([token_type_ids])\n        start_scores, end_scores = self.model(input_ids_tensor, token_type_ids=token_type_ids_tensor)\n        all_tokens = self.tokenizer.convert_ids_to_tokens(input_ids)  \n        ## We should use the scores to get some type of confidence in the answer,\n        ## and use that to decide which answer we finally take.\n        top_starts_ind, top_starts_score = _get_top_inds(start_scores, 1)\n        top_ends_ind, top_ends_score = _get_top_inds(end_scores, 1)\n        #print(f\"{top_starts_ind}:{top_ends_ind}\")\n        #print(f\"{top_starts_score}|{top_ends_score}\")\n        answer_str = ' '.join(all_tokens[torch.argmax(start_scores) : \n                              torch.argmax(end_scores) + 1])\n        return answer_str, top_starts_score, top_ends_score\n    \n    def _query_one_text(self, question: str, text: str) -> str:\n        \"\"\"\n        Runs the model on each section of text of max_tokens length, returning the\n        first answer found.\n        \"\"\"\n        question_ids = self._encode_question(question)\n        text_id_subsets = self._encode_text(text, len(question))        \n        best_starts_score, best_ends_score = 0, 0\n        best_answer = None\n        for text_ids in text_id_subsets:\n            input_ids = question_ids + text_ids\n            # print(self.tokenizer.decode(input_ids))\n            # print(len(input_ids))\n            answer, sub_best_starts_score, sub_best_ends_score = self._find_answer(input_ids)\n            if sub_best_ends_score > best_ends_score:\n                # print(f\"Found better end score ({sub_best_ends_score}) for answer {answer}\")\n                best_ends_score = sub_best_ends_score\n                best_starts_score = sub_best_starts_score\n                best_answer = answer\n            # print(answer)\n            ## Take the first answer found, regardless of anything else. Improve this!\n            #if _answer_ok(answer):\n            #    break\n        return best_answer, best_starts_score, best_ends_score\n    \n    def answer(self, question: str, max_texts = 1000):\n        \"\"\"\n        Runs the model for the input question on all texts (up to max_texts), \n        returning the first answer found.\n        \"\"\"\n        if max_texts is None:\n            max_texts = len(self.texts)\n        best_start_score, best_end_score = 0, 0\n        best_answer = None\n        for i, text in enumerate(self.texts):\n            if i > max_texts:\n                break\n            answer, text_best_start_score, text_best_end_score = self._query_one_text(question, text)\n            if text_best_end_score > best_end_score:\n                print(f\"Found better end score ({text_best_end_score.item()}) for answer '{answer}'\")\n                best_end_score = text_best_end_score\n                best_start_score = text_best_start_score\n                best_answer = answer\n            \n            print(answer)\n            ## Again take the first answer found, regardless of anything else. Improve this too!               \n            #if _answer_ok(answer):\n            #    break\n        return best_answer\n    \n","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"json_files = get_json_names()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = read_texts(json_files)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    for char in ('\\n', '.'):\n        text = text.replace(char, ' ')\n    return text","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I think the pretrained model I'm using is fixed at a maximum input sequence length (max_position_embeddings) of 512 tokens. So we will either have to find a pretrained model where this is larger; train our own version with this larger; or use some method where we walk along all the texts (or otherwise narrow them by search) and run on the < 512-length windows.  \n\nWe should remove citations - that [18] stuff  \n\nAnd we really should domain transfer."},{"metadata":{"trusted":true},"cell_type":"code","source":"## config = transformers.BertConfig(max_position_embeddings=10000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = transformers.BertTokenizer.from_pretrained(\n    'bert-base-uncased')\nmodel = transformers.BertForQuestionAnswering.from_pretrained(\n    'bert-large-uncased-whole-word-masking-finetuned-squad')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = texts[0]\ninput_text = \"[CLS] \" + question + \" [SEP] \" + text + \" [SEP]\"\ninput_ids = tokenizer.encode(input_text)[:512]\n\n## why 102?\ntoken_type_ids = [0 if i <= input_ids.index(102) else 1 for i in range(len(input_ids))] \n\ninput_ids_tensor = torch.tensor([input_ids])\ntoken_type_ids_tensor = torch.tensor([token_type_ids])\n\nstart_scores, end_scores = model(input_ids_tensor, token_type_ids=token_type_ids_tensor)\nall_tokens = tokenizer.convert_ids_to_tokens(input_ids)  ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t = torch.tensor([[46]])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_k = 3\ntop_starts = _get_top_inds(start_scores, top_k)\ntop_ends = _get_top_inds(end_scores, top_k)\nprint(top_starts)\nprint(top_ends)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts[0]","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"'VP3, and VP0 (which is further processed to VP2 and VP4 during virus assembly) (6). The P2 64 and P3 regions encode the non-structural proteins 2B and 2C and 3A, 3B (1-3) (VPg), 3C pro and 4 structural protein-coding region is replaced by reporter genes, allow the study of genome 68 replication without the requirement for high containment (9, 10) ( figure 1A ).\\nThe FMDV 5′ UTR is the largest known picornavirus UTR, comprising approximately 1300 71 nucleotides and containing several highly structured regions. The first 360 nucleotides at the 5′ 72 end are predicted to fold into a single large stem loop termed the S-fragment, followed by a The PKs were originally predicted in 1987 and consist of two to four tandem repeats of a ~48 86 nucleotide region containing a small stem loop and downstream interaction site (figure 1B) 87 (12). Due to the sequence similarity between the PKs (figure 1C), it is speculated that they 88 were formed by duplication events during viral replication, probably involving recombination. 89 Between two and four PKs are present in different virus isolates but no strain has been 90 identified with less than two PKs, emphasising their potential importance in the viral life cycle 91 (19, 20) . The presence of PKs has been reported in the 5′ UTR of other picornaviruses such as 92 author/funder. All rights reserved. No reuse allowed without permission. can occur in the absence of PKs at least one is required for wild-type (wt) replication. 104 Furthermore, competition experiments showed that extra copies of PKs conferred a replicative 105 advantage to genomes. Although replicons and full-length genomes lacking PKs were 106 replication-competent, no infectious virus was rescued from genomes containing less than one 107 PK copy. This is consistent with our earlier report describing the presence of putative 108 packaging signals in the PK region (22). 109 110 author/funder. All rights reserved. No reuse allowed without permission. Plasmid construction. 117 The FMDV replicon plasmids, pRep-ptGFP, and the replication-defective polymerase mutant 118 control, 3D-GNN, have already been described (10).\\nTo introduce mutations into the PK region, the pRep-ptGFP replicon plasmid was digested 121 with SpeI and KpnI and the resulting fragment inserted into a sub-cloning vector (pBluescript) 122 to create the pBluescript PK. PKs 3 and 4 were removed by digestion with HindIII and AatII 123 before insertion of a synthetic DNA sequence with PK 3 and 4 deleted. PKs 2, 3 and 4 were 124 deleted by PCR amplification using ΔPK 234 Forward primer and FMDV 1331-1311 reverse 125 primer, the resultant product was digested with HindIII and AatII and ligated into the 126 pBluescript PK vector. Complete PK deletion was achieved by introduction of an AflII site at 127 the 3′ end of the poly-C tract by PCR mutagenesis to create the sub-cloning vector, pBluescript 128 C11, which was then used to remove all the PKs by PCR mutagenesis using ΔPK 1234 forward 129 primer and FMDV 1331-1311 reverse primer. The modified PK sequences were removed from 130 the sub-cloning vectors and inserted into the pRep-ptGFP plasmid using NheI-HF and KpnI-131 HF.\\n132 133 author/funder. All rights reserved. No reuse allowed without permission.\\nThe copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint 7 Mutations to disrupt and reform PK structure were introduced using synthetic DNA by 134 digestion with AflII and AatII and ligation into a similarly digested pBluescript PK vector.\\nMutations were then introduced into the replicon plasmid as described above.\\nTo assess the effects of truncation of the poly-C-tract on replication the entire sequence was 137 removed. This was performed by PCR mutagenesis using primers C0 SpeI, and FMDV 1331- In vitro transcription. 143 In vitro transcription reactions for replicon assays were performed as described previously (28).\\nTranscription reactions to produce large amounts of RNA for SHAPE analysis were performed 145 with purified linear DNA as described above, and 1 μg of linearised DNA was then used in a 146 HiScribe T7 synthesis kit (NEB), before DNase treatment and purification using a PureLink FastQ files were quality checked using FastQC with poor quality reads filtered using the 225 Sickle algorithm. Host cell reads were removed using FastQ Screen algorithm and FMDV 226 reads assembled de novo into contigs using IDBA-UD (35). Contigs that matched the FMDV 227 library (identified using Basic Local ALighnment Search Tool (BLAST)) were assembled 228 author/funder. All rights reserved. No reuse allowed without permission.\\nThe copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint into consensus sequences using SeqMan Pro software in the DNA STAR Lasergene 13 229 package (DNA STAR) (36). The SHAPE data largely agreed with the predicted structures with the stems of PK 1, 2 and 3, interacting nucleotides showed little to no reactivity, suggesting NMIA could not interact with 300 author/funder. All rights reserved. No reuse allowed without permission.\\nThe copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint 14 these nucleotides either due to the predicted base pairing or steric hindrance (figure 2B). The\\nNMIA reactivity for the interacting nucleotides in the stem-loops with downstream residues of 302 PK 1, 2 and 3 again largely agreed with the predicted structure, although the SHAPE data 303 suggests that there might be fewer interactions than previously predicted. However, differences 304 here could be due to heterogeneity in the formation of PKs in this experiment. The evidence 305 for loop-downstream interaction was weaker for PK4. The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint\\norientation. 351 Since removal of all four PKs resulted in a significant decrease in replication, the minimal 352 requirements to maintain wt levels of replication were investigated. As near wt level of 353 replication was observed when only one PK was present, all further mutagenesis was 354 performed in a C11 replicon plasmid containing only PK 1. In addition, the orientation of PK 1 was reversed by \"flipping\" the nucleotide sequence to 367 potentially facilitate hybridisation of the loop with upstream rather than downstream sequences.\\nChanging the orientation of the PK reduced replicon replication to a similar level seen in the replication decreased until at passage three there is a 2.5 fold reduction compared to that of 398 author/funder. All rights reserved. No reuse allowed without permission.\\nThe copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint passage 0 (figure 5B). Therefore, it appears that replicons with a single PK are at a competitive 399 disadvantage compared to those with two or more. The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint 20 of infectious virus despite being able to replicate after transfection into cells, is consistent with 448 a requirement for RNA structure within the PK region being required for virus assembly. The 5′ UTR of FMDV is unique amongst picornaviruses due to its large size and the presence 454 of multiple RNA elements, some of which still have unknown function. One of these features 455 is a series of repeated PKs varying in number from 2-4, depending on virus strain. In this study, 456 we sequentially deleted or mutated the PKs to help understand their role in the viral life cycle. 457 We also confirmed the predicted PK structures by SHAPE mapping, although there may be Although all viruses isolated to date contain at least two PKs, replicons or viruses containing a 464 single PK were still replication competent. However, replicons with more than a single PK 465 were found to have a competitive advantage over replicons with a single PK when sequentially 466 passaged. Replicons lacking all PKs displayed poor passaging potential even when co-467 transfected with yeast tRNA, reinforcing the observation of a significant impact in replication.\\nMoreover, viruses recovered from genomes with reduced numbers of PKs were slower growing 469 and produced smaller plaques. In addition, these differences were more pronounced in more PKs is functionally competent as no differences was seen between replicons congaing a single 472 author/funder. All rights reserved. No reuse allowed without permission.\\nThe copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint 21 copy of PK1 or PK4. This observation is consistent with a previous report of deletion of PK1, 473 along with the Poly-C-tract, with no adverse effect in viral replication (37). This also supports 474 our findings that the truncation of the Poly-C-tract to create the C11 construct had no effect on 475 replicon replication in the cell lines tested. As has been described with Mengo virus, it is 476 possible that the role of the poly-C-tract is essential in other aspects of the viral lifecycle which 477 cannot be recapitulated in a standard tissue culture system (39).\\nThe presence of at least two PKs in all viral isolates sequenced so far suggests that multiple 480 PKs confer a competitive advantage in replication. Here we showed by sequential passage that 481 replicons containing at least two PKs were maintained at a level similar to wt, but replicons 482 containing only one PK showed a persistent decline. It is unclear why some viral isolates 483 contain two, three or four PKs is still unknown, but this may be stochastic variation or may 484 reflect subtle effects of host range or geographical localisation. The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint author/funder. All rights reserved. No reuse allowed without permission.\\nThe copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint The copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint Significance is shown comparing the replication of C11 PK disrupt and C11 PK restore (Aii). Significance shown is compared to wt replicon. Error bars are calculated by SEM, n = 3, * P 673 < 0.05, **** P < 0.0001. 674 author/funder. All rights reserved. No reuse allowed without permission.\\nThe copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint 33 675 author/funder. All rights reserved. No reuse allowed without permission.\\nThe copyright holder for this preprint (which was not peer-reviewed) is the . https://doi.org/10.1101/2020.01.10.901801 doi: bioRxiv preprint '"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"answerer = Answerer(model=model, tokenizer=tokenizer, texts=texts)\nquestion = \"How are mutations introduced to PK regions?\"\nquestion = \"How bad is the flu?\"\nquestion = \"What are PKs?\"\n# question = \"What is a dog?\"\n\n","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"answerer.answer(question, 1)","execution_count":17,"outputs":[{"output_type":"stream","text":"Found better end score (4.27646541595459) for answer 'c1 ##1'\nc1 ##1\nFound better end score (4.5037736892700195) for answer 'south korea'\nsouth korea\n","name":"stdout"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"'south korea'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"## What if we cut _at_ an answer? We need overlapping windows!","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}